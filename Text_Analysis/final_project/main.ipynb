{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {  
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ïú†ÌäúÎ∏å ÎßõÏßë ÏòÅÏÉÅ ÏßÑÏúÑ ÌåêÎ≥Ñ: LLM fine-tuning"
      ],
      "metadata": {
        "id": "-C8lGA0KlPQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. ÌôòÍ≤Ω Íµ¨Ï∂ï**"
      ],
      "metadata": {
        "id": "S5GlGQgXsWGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏΩîÎû© ÏãúÏûë Ïãú Ìïú Î≤àÎßå Ïã§Ìñâ\n",
        "!pip install --upgrade pip\n",
        "!pip install google-api-python-client pandas\n",
        "!pip install google-api-python-client transformers datasets\n",
        "!pip install torch\n",
        "!pip install -q transformers accelerate peft datasets bitsandbytes trl yt_dlp google-api-python-client\n",
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuySEMDQ48yH",
        "outputId": "0a719c27-1cc9-423e-c515-0704ef3fdc44"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.187.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.187.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import yt_dlp\n",
        "import json"
      ],
      "metadata": {
        "id": "bHcPOvmfBMIN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. LLM ÌïôÏäµÏö© Îç∞Ïù¥ÌÑ∞ ÏàòÏßë**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VHdbKqVUk6zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.1 Îç∞Ïù¥ÌÑ∞ ÏàòÏßë**\n",
        "\n",
        "*   Ïú†ÌäúÎ∏å ÎßõÏßë ÏÜåÍ∞ú ÏòÅÏÉÅ 5Í∞ú\n",
        "*   Ïú†ÌäúÎ∏å API ÏÇ¨Ïö©\n",
        "*   ÎåìÍ∏Ä Îç∞Ïù¥ÌÑ∞ ÏàòÏßë\n",
        "*   Ï†ÑÏ≤òÎ¶¨ X\n",
        "\n"
      ],
      "metadata": {
        "id": "sU7C_aq-tzau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïú†ÌäúÎ∏å ÎåìÍ∏Ä ÏàòÏßë Ìï®Ïàò\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def get_youtube_comments(api_key, video_id, max_comments=200):\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(comments) < max_comments:\n",
        "        request = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            pageToken=next_page_token,\n",
        "            maxResults=100,\n",
        "            textFormat=\"plainText\"\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
        "            comments.append(text)\n",
        "            if len(comments) >= max_comments:\n",
        "                break\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n"
      ],
      "metadata": {
        "id": "hpBdzFiatj6Z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.2 ÎåìÍ∏Ä Í∞êÏÑ± Î∂ÑÏÑù**\n",
        "\n",
        "\n",
        "\n",
        "*   Î™®Îç∏: KcELECTRA-base\n",
        "*   ÎßõÏßë ÎùºÎ≤®: Í∞êÏÑ±Î∂ÑÏÑù score 4Ï†ê Ïù¥ÏÉÅÏùº Í≤ΩÏö∞ ÎßõÏßë\n",
        "*   train.josnlÌååÏùº Ï†ÄÏû•\n",
        "\n"
      ],
      "metadata": {
        "id": "vtyj0pV0v4jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Í∞êÏÑ± Î∂ÑÏÑù Î™®Îç∏ Î°úÎìú\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhO5aIwqtr-1",
        "outputId": "0287477d-65d5-4f5b-fe1c-1bca971bc78c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎßõÏßë ÎùºÎ≤® Ï°∞Í±¥ ÏÑ§Ï†ï\n",
        "\n",
        "def label_to_food(label):\n",
        "    star = int(label[0])   # \"5 stars\" ‚Üí 5\n",
        "    if star >= 4:\n",
        "        return \"1\"    # ÎßõÏßë\n",
        "    else:\n",
        "        return \"0\"    # ÎπÑÎßõÏßë\n"
      ],
      "metadata": {
        "id": "GVn6mMBkttmh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT Í∞êÏÑ±Î∂ÑÏÑù -> ÎùºÎ≤®ÎßÅ -> JSONLÌååÏùº Ï†ÄÏû•\n",
        "\n",
        "import re\n",
        "import json\n",
        "import torch\n",
        "\n",
        "\n",
        "def extract_video_id(url):\n",
        "    match = re.search(r\"v=([^&]+)\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "\n",
        "def make_train_jsonl(api_key, url_list, output_path=\"train.jsonl\"):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "\n",
        "        for url in url_list:\n",
        "            video_id = extract_video_id(url)\n",
        "            if not video_id:\n",
        "                print(\"URLÏóêÏÑú videoId Ï∂îÏ∂ú Ïã§Ìå®:\", url)\n",
        "                continue\n",
        "\n",
        "            comments = get_youtube_comments(api_key, video_id)\n",
        "            # -------------------------------\n",
        "            # Í∏∏Ïù¥ Ï†úÌïúÏúºÎ°ú ÏûòÎùºÎÇ¥Îäî Ìï®Ïàò\n",
        "            # -------------------------------\n",
        "            def truncate_text(text, tokenizer, max_len=512):\n",
        "                tokens = tokenizer.tokenize(text)\n",
        "                if len(tokens) > max_len:\n",
        "                    tokens = tokens[:max_len]\n",
        "                return tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "            # -------------------------------\n",
        "            # BERT Í∞êÏÑ± Î∂ÑÏÑù (512 Ï†úÌïú Ìè¨Ìï®)\n",
        "            # -------------------------------\n",
        "            def safe_sentiment(text, tokenizer, model):\n",
        "                # ÌÖçÏä§Ìä∏ Í∏∏Ïù¥ Ï§ÑÏù¥Í∏∞\n",
        "                text = truncate_text(text, tokenizer)\n",
        "\n",
        "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(**inputs)\n",
        "\n",
        "                logits = outputs.logits\n",
        "                probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "                label_idx = torch.argmax(probs).item()\n",
        "                score = probs[0][label_idx].item()\n",
        "\n",
        "                # huggingface pipeline ÌòïÏãùÍ≥º ÎèôÏùºÌïòÍ≤å Î∞òÌôò\n",
        "                return [{\"label\": str(label_idx), \"score\": score}]\n",
        "\n",
        "\n",
        "            for c in comments:\n",
        "                res = safe_sentiment(c, tokenizer, model)[0]\n",
        "                label = label_to_food(res[\"label\"])\n",
        "\n",
        "                item = {\n",
        "                    \"instruction\": \"Îã§Ïùå Ïú†ÌäúÎ∏å ÎåìÍ∏ÄÏù¥ ÎßõÏßëÏùÑ Í∏çÏ†ïÏ†ÅÏúºÎ°ú ÌèâÍ∞ÄÌñàÎäîÏßÄ ÌåêÎ≥ÑÌïòÏãúÏò§.\",\n",
        "                    \"input\": c,\n",
        "                    \"output\": label\n",
        "                }\n",
        "\n",
        "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    print(\"JSONL ÏÉùÏÑ± ÏôÑÎ£å:\", output_path)\n"
      ],
      "metadata": {
        "id": "yR_Jo_5utvMR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Í∞úÏù∏ APIÌÇ§ ÏûÖÎ†•\n",
        "API_KEY = \"\"\n",
        "\n",
        "# ÌïôÏäµÌï† ÎßõÏßë ÏòÅÏÉÅ url\n",
        "urls = [\n",
        "    \"https://www.youtube.com/watch?v=pgpqzM7Gow8\",\n",
        "    \"https://www.youtube.com/watch?v=yRwhSGg9F2g&pp=ygUG66eb7KeR\",\n",
        "    \"https://www.youtube.com/watch?v=66_hgJFbDuY&pp=ygUG66eb7KeR\",\n",
        "    \"https://www.youtube.com/watch?v=9u_TNpoR2Go&pp=ygUG66eb7KeR\",\n",
        "    \"https://www.youtube.com/watch?v=we7qK9zg8rM&pp=ygUG66eb7KeR\"\n",
        "]\n",
        "\n",
        "make_train_jsonl(API_KEY, urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd9BLKGZtxOu",
        "outputId": "46f4a363-f1fa-42e2-80b9-ead74f2ca409"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSONL ÏÉùÏÑ± ÏôÑÎ£å: train.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. LLM Fine-tuning + SFT**"
      ],
      "metadata": {
        "id": "80f0CHhBAHx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Î™®Îç∏ Î°úÎìú**\n",
        "*   Î™®Îç∏: QLoRA\n",
        "\n"
      ],
      "metadata": {
        "id": "IXzYoJmX0W8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8IoQyLtI0Of",
        "outputId": "7675b07c-e37d-4edb-efe5-14fcd042bdfb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,179,072 || all params: 1,545,893,376 || trainable%: 0.1410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2 SFT ÌååÏù∏ ÌäúÎãù ÏÑ§Ï†ï**"
      ],
      "metadata": {
        "id": "yiNzd1MY03Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"train.jsonl\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "def format_example(example):\n",
        "    return f\"\"\"[INST] {example['instruction']}\n",
        "\n",
        "{example['input']} [/INST]\n",
        "\n",
        "{example['output']}\"\"\"\n",
        "\n",
        "dataset = dataset.map(lambda x: {\"text\": format_example(x)})\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./out\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=10,\n",
        "    max_steps=150,       # ÌïôÏäµÎüâ Ï°∞Ï†à\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    args=training_args,\n",
        "    processing_class=tokenizer,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "4151a4a8f58d46fca813853abcd90a5a",
            "3c08c4fde0dd401ea6b21466896804eb",
            "c5984a3f931b4df99c32f34848937bc3",
            "1820a1eb8d2348f5bc1baf962c124ff8",
            "da96a875444446ea813f9c3296592b23",
            "736cab8007d14d338fa4fda4e87cba8d",
            "22d33b4a8ca7496290ea5b0c77f7842c",
            "8b6cb15370434874867cbf963e1aa718",
            "7b09366bd6db42e0ac709488e356fe04",
            "cc4a40a25cda44bf9700c34a0ff5db12",
            "e08f27fbf87e4dacb61c8aa045cdd6e3",
            "262d2282ce2c49ce8c7c7195a76c4171",
            "482b7b57e07843d48b2a98f3248b8a7e",
            "7908eb35b31c4586b8e125c66d3401fc",
            "e144a41ca78c4a6bace4139f80796901",
            "e2568b9276bc4256a9d5ca7fe06f9a0a",
            "ae5f626e883e4dd9b9281ea12035afb3",
            "a959907877c6429b9440ff8a8edabba5",
            "f8b06cdaf6c2430c8a5a825e69b89bb8",
            "63190a78dbe9472eb58f98b7b8878ff9",
            "0738ea424d924f71b95fc8a56c9af9ed",
            "298fcc33ba794f33818b1823c7f566df",
            "cd27d83e04c745c49105af43a5c5e5eb",
            "83d921b51d064c4a9d792f5bc1e6a702",
            "161f1407507e42779384f6383b88d6d0",
            "998b6491a7bb4a1ba27c9af002853419",
            "562f53fb9b0d493fa5d8107fc3eeccd3",
            "99ec785716b24e01901612744b1acf9a",
            "6e5ffa330e4c48269d4e6bfa46db0de5",
            "f921bd21a49a4241a709abc03d91e2cb",
            "758d51f069c642dcbf8d3ed9347d5f74",
            "378008dd90c74d7fa63f0c59b66d198c",
            "e2485e8cc932481d959817290ed3de3f",
            "ad000b9c669c4a799a56e52b32f84940",
            "3d876b45f9da49bd92fda48706757e36",
            "7123160ddb3e4ba0a8457b77fdad40bb",
            "64000cb47b4a4be2bdb1d42db5dcefe5",
            "3fab6c599d5f47478be06596e9af74f8",
            "6950b3cc9f6d4bd792f1972254d36a35",
            "686630dd73844e3f80b251ec5a6d6626",
            "14dc78d8861d4315aa69f19e87b8ae56",
            "974aa9667e7e4572951c21463f61742b",
            "7ddcab8793af4e978840b10b9b676ec5",
            "26344852f59448849763611ddd6ae924",
            "aac9484b892f46089316a87f6fee2a52",
            "d6f061cc06cf413394102da43b49dc4f",
            "714de5067af24ba6bf80b669f1351a79",
            "9fe7d0ef4d5542a495d0989e33d1a8ad",
            "c27d8c6263244069a5e0d49aea769c41",
            "a24e243365bf45e382d59415703e37ad",
            "194967ce2e9a451da1c72edf880be6d5",
            "b13bff4f96a643c29b0fadbbf1019184",
            "5577e1a4d7b34eed98fd5f9f25744890",
            "b26511fd8d8b4f86a4048a9867c1c987",
            "6927264fe47a4d9f92fcfb19260f7d4a"
          ]
        },
        "id": "CbGVbxz8ZPTk",
        "outputId": "3afa17d6-9d2a-401f-d4b4-e7e36fe77946"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4151a4a8f58d46fca813853abcd90a5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/764 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "262d2282ce2c49ce8c7c7195a76c4171"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to train dataset:   0%|          | 0/764 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd27d83e04c745c49105af43a5c5e5eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/764 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad000b9c669c4a799a56e52b32f84940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/764 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aac9484b892f46089316a87f6fee2a52"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌïôÏäµ Ïã§Ìñâ\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained(\"./finetuned-model\")\n",
        "tokenizer.save_pretrained(\"./finetuned-model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "collapsed": true,
        "id": "DHt33EPQDI5l",
        "outputId": "fd39d3e5-d62a-4de4-9f2c-cc44a5923360"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 01:56, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.902400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.272400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.851300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.607700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.353900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.293400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.343800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.240700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.427500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.160300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.975600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.233000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.162700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.171700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned-model/tokenizer_config.json',\n",
              " './finetuned-model/special_tokens_map.json',\n",
              " './finetuned-model/chat_template.jinja',\n",
              " './finetuned-model/vocab.json',\n",
              " './finetuned-model/merges.txt',\n",
              " './finetuned-model/added_tokens.json',\n",
              " './finetuned-model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Í≤∞Í≥º**"
      ],
      "metadata": {
        "id": "i3MohNqP1CaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 **ÌÖåÏä§Ìä∏Ïö© Îç∞Ïù¥ÌÑ∞ Î°úÎìú**"
      ],
      "metadata": {
        "id": "2MGsCdf81oax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
        "\n",
        "def get_youtube_comments(video_id, max_comments=50):\n",
        "    comments = []\n",
        "\n",
        "    response = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        maxResults=100,\n",
        "        textFormat=\"plainText\"\n",
        "    ).execute()\n",
        "\n",
        "    while response and len(comments) < max_comments:\n",
        "        for item in response.get(\"items\", []):\n",
        "            text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
        "            comments.append(text)\n",
        "\n",
        "            if len(comments) >= max_comments:\n",
        "                break\n",
        "\n",
        "        if \"nextPageToken\" not in response:\n",
        "            break\n",
        "\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=response[\"nextPageToken\"],\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "    return \"\\n\".join(comments)\n"
      ],
      "metadata": {
        "id": "-ekLJmpqBVMy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. ÎßõÏßë ÌåêÎ≥Ñ**"
      ],
      "metadata": {
        "id": "JALWos112ALi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌååÏù∏ÌäúÎãùÎêú Î™®Îç∏ Î°úÎìú\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./finetuned-model\", fix_mistral_regex=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"./finetuned-model\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_video_id(url):\n",
        "    pattern = r\"(?:v=|youtu\\.be/)([A-Za-z0-9_-]{11})\"\n",
        "    match = re.search(pattern, url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "\n",
        "def predict_youtube(url):\n",
        "    video_id = extract_video_id(url)\n",
        "    if not video_id:\n",
        "        print(\"‚ùå ÏòÅÏÉÅ IDÎ•º Ï∂îÏ∂úÌï† Ïàò ÏóÜÏùå.\")\n",
        "        return\n",
        "\n",
        "    comments_text = get_youtube_comments(video_id)\n",
        "\n",
        "    # üîπ chat_template ÏÇ¨Ïö© (Í∂åÏû•)\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"ÏïÑÎûòÎäî Ïú†ÌäúÎ∏å ÏòÅÏÉÅ ÎåìÍ∏ÄÎì§Ïù¥Îã§. Ïù¥ ÎåìÍ∏ÄÏùÑ Í∏∞Î∞òÏúºÎ°ú Ïù¥ ÏòÅÏÉÅÏù¥ ÎßõÏßëÏù∏ÏßÄ ÎÖ∏ÎßõÏßëÏù∏ÏßÄ ÌåêÎã®Ìï¥Îùº.\n",
        "\n",
        "Ï∂úÎ†• ÌòïÏãù:\n",
        "Ï≤´ Îã®Ïñ¥Îäî 'ÎßõÏßë' ÎòêÎäî 'ÎÖ∏ÎßõÏßë'ÏúºÎ°ú ÏãúÏûëÌïòÍ≥†, Í∑∏ Îí§Ïóê Ìïú Î¨∏Ïû•ÏúºÎ°ú ÏßßÍ≤å Ïù¥Ïú†Î•º ÏÑ§Î™ÖÌï¥Îùº.\n",
        "\n",
        "ÏòàÏãú:\n",
        "ÎßõÏßë Í∏çÏ†ïÏ†ÅÏù∏ ÎåìÍ∏ÄÏù¥ ÎßéÍ≥† ÏùåÏãùÏù¥ ÎßõÏûàÎã§Îäî ÌèâÍ∞ÄÍ∞Ä ÎßéÏùå\n",
        "ÎÖ∏ÎßõÏßë Î∂ÄÏ†ïÏ†ÅÏù∏ ÎåìÍ∏ÄÏù¥ ÎßéÍ≥† ÏÑúÎπÑÏä§Í∞Ä Î∂àÏπúÏ†àÌïòÎã§Îäî ÏùòÍ≤¨Ïù¥ ÎßéÏùå\n",
        "\n",
        "ÎåìÍ∏Ä:\n",
        "{comments_text}\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    # üîπ ÎãµÎ≥Ä Î∂ÄÎ∂ÑÎßå Ï∂îÏ∂ú\n",
        "    if \"[/INST]\" in decoded:\n",
        "        content = decoded.split(\"[/INST]\")[-1].strip()\n",
        "    else:\n",
        "        # chat_template ÏÇ¨Ïö© Ïãú assistant ÎãµÎ≥ÄÎßå Ï∂îÏ∂ú\n",
        "        if \"assistant\" in decoded.lower():\n",
        "            content = decoded.split(\"assistant\")[-1].strip()\n",
        "        else:\n",
        "            content = decoded.strip()\n",
        "\n",
        "    # [INST] ÌÉúÍ∑∏Í∞Ä ÎÇ®ÏïÑÏûàÏúºÎ©¥ Ï†úÍ±∞\n",
        "    if content.startswith(\"[INST]\"):\n",
        "        content = content.replace(\"[INST]\", \"\").strip()\n",
        "\n",
        "    content = content.replace(\"\\n\", \" \").strip()\n",
        "\n",
        "    words = content.split()\n",
        "    result_word = words[0] if words else \"ÌåêÎã® Î∂àÍ∞Ä\"\n",
        "    reason = \" \".join(words[1:]) if len(words) > 1 else \"ÏÑ§Î™Ö ÏóÜÏùå\"\n",
        "\n",
        "    print(\"üçΩÔ∏è ÏµúÏ¢Ö ÌåêÎã®:\", result_word)\n",
        "    print(\"üìù ÌåêÎã® Ïù¥Ïú†:\", reason)\n"
      ],
      "metadata": {
        "id": "_0hULyBXDO5w"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌÖåÏä§Ìä∏ Ïã§Ìñâ\n",
        "\n",
        "# ÎßõÏßë ÏúºÎ°ú Î≥¥Ïù¥Îäî ÏòÅÏÉÅ url ÏûÖÎ†•\n",
        "test_url = \"https://www.youtube.com/watch?v=vJT_Hs4VHMI&pp=ygUN66eb7KeRIOyGjOqwnA%3D%3D\"\n",
        "predict_youtube(test_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eWIP80XtFLm",
        "outputId": "703b1f0c-48b8-4f9d-e43b-aaf2543cd6a1"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçΩÔ∏è ÏµúÏ¢Ö ÌåêÎã®: ÎßõÏßë\n",
            "üìù ÌåêÎã® Ïù¥Ïú†: Í∏çÏ†ïÏ†ÅÏù∏ ÎåìÍ∏ÄÏù¥ ÎßéÍ≥†, ÎßéÏùÄ ÏÇ¨ÎûåÎì§ÏóêÍ≤åÊé®ËçêÎêòÏñ¥ Î≥¥Í∏∞Ïóê Ï¢ãÎã§Îäî ÌèâÍ∞ÄÍ∞Ä ÎßéÎã§. ÌäπÌûà, Ïó¨Îü¨ Í∞ÄÏßÄ Îã§ÏñëÌïú ÏùåÏãùÏùÑ Ï†úÍ≥µÌïòÎ©∞, Í∞ÄÍ≤©Í≥º Í∞ÄÏÑ±ÎπÑÎèÑ Îß§Ïö∞ Ïö∞ÏàòÌïòÎã§Îäî Ï†êÏù¥ ÎààÏóê ÎùàÎã§. ÎòêÌïú, ÎßéÏùÄ ÏÇ¨ÎûåÎì§ÏóêÍ≤å Ï∂îÏ≤úÎ∞õÏïÑ ÎßéÏùÄ Í¥ÄÏã¨ÏùÑ Î∞õÍ≥† ÏûàÎäî Î™®ÏäµÏù¥ Î≥¥Ïù∏Îã§. Ïù¥Îü¨Ìïú ÏöîÏÜåÎì§ÏùÑ Ï¢ÖÌï©ÌïòÎ©¥ Ïù¥ ÏòÅÏÉÅÏù¥ ÎßõÏßëÏúºÎ°ú ÌåêÎã®ÎêúÎã§.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎßõÏßëÍ≥º Í¥ÄÎ†® ÏóÜÎäî ÏòÅÏÉÅ url ÏûÖÎ†•\n",
        "test_url = \"https://www.youtube.com/watch?v=9HMo07DbCq0\"\n",
        "predict_youtube(test_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN5zyEhgDHJ4",
        "outputId": "3912e933-6272-468d-99e7-491aa0fafdd9"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçΩÔ∏è ÏµúÏ¢Ö ÌåêÎã®: ÎÖ∏ÎßõÏßë\n",
            "üìù ÌåêÎã® Ïù¥Ïú†: Î∂ÄÏ†ïÏ†ÅÏù∏ ÎåìÍ∏ÄÏù¥ ÎßéÍ≥†, Íµ¨ÎèÖÏûêÎ•º ÏúÑÌïú Î†àÌè¨Ìä∏Í∞Ä ÏïÑÎãå ÏùºÎ∞òÏ†ÅÏù∏ ÌÖçÏä§Ìä∏Î°úÎßå ÏûëÏÑ±ÎêòÏñ¥ ÏûàÏñ¥ÏÑú ÌåêÎã®ÌïòÍ∏∞ Ïñ¥Î†µÏäµÎãàÎã§. Í∑∏Îü¨ÎÇò Ìï¥Îãπ ÏßÄÏó≠ÏùÑ Î∞©Î¨∏Ìïú ÎßåÌÅº Îã§ÏñëÌïú Ï†ïÎ≥¥Î•º ÏàòÏßëÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§.\n"
          ]
        }
      ]
    }
  ]
}